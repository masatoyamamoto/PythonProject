Index: 20200506_getDataFromSumo.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Libraries\r\nfrom bs4 import BeautifulSoup\r\nimport requests\r\nimport pandas as pd\r\nfrom pandas import Series, DataFrame\r\nimport time\r\nimport csv\r\n\r\n# URL 試しに、千代田区の中古マンション購入の検索画面トップ\r\nurl = \"https://suumo.jp/jj/bukken/ichiran/JJ010FJ001/?ar=030&bs=011&ta=13&jspIdFlg=patternShikugun&sc=13101&kb=1&kt=9999999&mb=0&mt=9999999&ekTjCd=&ekTjNm=&tj=0&cnb=0&cn=9999999&srch_navi=1\"\r\n\r\n# データ取得\r\nresult = requests.get(url)\r\nc = result.content\r\n\r\n# HTMLを元にオブジェクトを作る\r\nsoup = BeautifulSoup(c, 'lxml')\r\n\r\n# 物件リストを切り出し\r\nsummary = soup.find(\"div\", {'id': 'js-bukkenList'})\r\n\r\n# ページ数取得 もっと良い方法がありそう。\r\nbody = soup.find(\"body\")\r\npages = body.find_all(\"div\", {'class': 'pagination pagination_set-nav'})\r\npages_text = str(pages)\r\npages_split = pages_text.split('</a></li>\\n</ol>')\r\npages_split0 = pages_split[0]\r\npages_split1 = pages_split0[-3:]\r\npages_split2 = pages_split1.replace('\">', '')\r\npages_split3 = int(pages_split2)\r\n\r\n# URLを入れるリスト\r\nurls = [url]\r\n\r\n# 2ページ目から最後のページまでを格納\r\nfor i in range(pages_split3 - 1):\r\n    pg = str(i + 2)\r\n    url_page = url + '&pn=' + pg\r\n    urls.append(url_page)\r\n\r\nname = []  # マンション名\r\naddress = []  # 住所\r\nlocations0 = []  # 立地1つ目（最寄駅/徒歩~分）\r\nlocations1 = []  # 立地2つ目（最寄駅/徒歩~分）\r\nlocations2 = []  # 立地3つ目（最寄駅/徒歩~分）\r\nage = []  # 築年数\r\nheight = []  # 建物高さ\r\nfloor = []  # 階\r\nrent = []  # 賃料\r\nadmin = []  # 管理費\r\nothers = []  # 敷/礼/保証/敷引,償却\r\nfloor_plan = []  # 間取り\r\narea = []  # 専有面積\r\n\r\n# 各ページで以下の動作をループ\r\nfor url in urls:\r\n    # 物件リストを切り出し\r\n    result = requests.get(url)\r\n    c = result.content\r\n    soup = BeautifulSoup(c)\r\n    summary = soup.find(\"div\", {'id': 'js-bukkenList'})\r\n\r\n    # マンション名、住所、立地（最寄駅/徒歩~分）、築年数、建物高さが入っているcassetteitemを全て抜き出し\r\n    cassetteitems = summary.find_all(\"div\", {'class': 'cassette'})\r\n\r\n\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- 20200506_getDataFromSumo.py	(revision 558f89efcff44be5a884d25f4ea2ae3481302fd5)
+++ 20200506_getDataFromSumo.py	(date 1590229761544)
@@ -57,11 +57,13 @@
     # 物件リストを切り出し
     result = requests.get(url)
     c = result.content
-    soup = BeautifulSoup(c)
+    soup = BeautifulSoup(c, "lxml")
     summary = soup.find("div", {'id': 'js-bukkenList'})
 
-    # マンション名、住所、立地（最寄駅/徒歩~分）、築年数、建物高さが入っているcassetteitemを全て抜き出し
-    cassetteitems = summary.find_all("div", {'class': 'cassette'})
+    # マンション名、住所、立地（最寄駅/徒歩~分）、築年数、建物高さが入っているを全て抜き出し
+    dataSet = summary.find_all(class_ = "dottable-fix")
+    print(summary.prettify())
+    print(dataSet)
 
 
 
Index: .idea/dictionaries/MasatoMaxYamamoto.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- .idea/dictionaries/MasatoMaxYamamoto.xml	(date 1589013931645)
+++ .idea/dictionaries/MasatoMaxYamamoto.xml	(date 1589013931645)
@@ -0,0 +1,3 @@
+<component name="ProjectDictionaryState">
+  <dictionary name="MasatoMaxYamamoto" />
+</component>
\ No newline at end of file
Index: 20200602_getDataFromSuumo_2.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- 20200602_getDataFromSuumo_2.py	(date 1591366497528)
+++ 20200602_getDataFromSuumo_2.py	(date 1591366497528)
@@ -0,0 +1,35 @@
+# Libraries
+from bs4 import BeautifulSoup
+import requests
+import pandas as pd
+from pandas import Series, DataFrame
+import time
+import csv
+
+# URL 試しに、千代田区の中古マンション購入の検索画面トップ
+url = "https://suumo.jp/jj/bukken/ichiran/JJ012FC002/?ar=030&bs=011&cn=9999999&cnb=0&ekTjCd=&ekTjNm=&kb=1&kt=9999999&mb=0&mt=9999999&sc=13101&ta=13&tj=0&bknlistmodeflg=2&pc=30&pn=1"
+
+# データ取得
+result = requests.get(url)
+c = result.content
+
+# HTMLを元にオブジェクトを作る
+soup = BeautifulSoup(c, 'lxml')
+
+summary = soup.find("div", {'id': 'js-bukkenList'})
+
+bukkenData = summary.find_all("div", {"class": "property_unit-content"})
+bukken_1 = bukkenData[0]
+
+# まずは物件毎のデータ取得
+title = bukken_1.find("h2", {"class": "property_unit-title_wide"}).find("a").text
+dataSet = bukken_1.find_all("table")
+
+a = 1
+for i in dataSet:
+    # if a % 2 == 1: print(str(a/2+0.5) + '----------------------')
+    a += 1
+    rows = i.find_all("dd")
+    for j in rows:
+        print(":")
+        print(j.text)
Index: 20200523_tempFile.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- 20200523_tempFile.py	(date 1591359313476)
+++ 20200523_tempFile.py	(date 1591359313476)
@@ -0,0 +1,38 @@
+# Libraries
+from bs4 import BeautifulSoup
+import requests
+import pandas as pd
+from pandas import Series, DataFrame
+import time
+import csv
+
+# URL 試しに、千代田区の中古マンション購入の検索画面トップ
+url = "https://suumo.jp/jj/bukken/ichiran/JJ010FJ001/?ar=030&bs=011&ta=13&jspIdFlg=patternShikugun&sc=13101&kb=1&kt=9999999&mb=0&mt=9999999&ekTjCd=&ekTjNm=&tj=0&cnb=0&cn=9999999&srch_navi=1"
+
+# データ取得
+result = requests.get(url)
+c = result.content
+
+# HTMLを元にオブジェクトを作る
+soup = BeautifulSoup(c, 'lxml')
+
+# 物件リストを切り出し
+summary = soup.find("div", {'id': 'js-bukkenList'})
+dataSet = summary.find_all("table")
+name = summary.find_all()
+price = summary.find_all("span", {'class': 'dottable-value'})
+
+
+a = 1
+for i in dataSet:
+    if a % 2 == 1: print(str(a/2+0.5) + '----------------------')
+    a += 1
+    rows = i.find_all("tr")
+
+    for j in rows:
+        row = j.find_all("dd")
+        for k in row:
+            print(k.text)
+    print(price[a-1].text)
+
+# print(summary.prettify())
